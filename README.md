# Нейронные сети

## Введение в нейронные сети

Этот курс, созданный Сергеем Балакириевым, предлагает детальное введение в нейронные сети и их применение. 
Оригинальный видео-контент: https://youtube.com/playlist?list=PLA0M1Bcd0w8yv0XGiF1wjerjSZVSrYbjh&si=cHJfbDbLf4NLIbwJ
Оригинальный консект: https://proproprogs.ru/neural_network
Оригинальный код: https://github.com/selfedu-rus/neural-network

Курс дополняется примерами и пояснениями с использованием ChatGPT для лучшего понимания материалов.

### Структура курса

1. **Полносвязные нейронные сети**
    - **Структура и принцип работы полносвязных нейронных сетей**
    - **Персептрон**: возможности классификации образов, задача XOR
    - **Back propagation**: алгоритм обучения по методу обратного распространения
    - **Ускорение обучения**: начальные веса, стандартизация, подготовка выборки
    - **Переобучение**: что это и как этого избежать, критерии останова обучения
    - **Функции активации**, критерии качества работы НС
    - **Keras**: установка и первое знакомство
    - **Keras**: обучение сети распознаванию рукописных цифр
    - **Как нейронная сеть распознает цифры**
    - **Оптимизаторы в Keras**, формирование выборки валидации
    - **Dropout**: метод борьбы с переобучением нейронной сети
    - **Batch Normalization (батч-нормализация)**: что это такое?

2. **Сверточные нейронные сети**
    - **Как работают сверточные нейронные сети**
    - **Создание сверточной нейронной сети в Keras**
    - **Примеры архитектур сверточных сетей VGG-16 и VGG-19**
    - **Теория стилизации изображений (Neural Style Transfer)**
    - **Перенос стилей изображений с помощью Keras и Tensorflow**
    - **Как нейронная сеть раскрашивает изображения**

3. **Рекуррентные нейронные сети**
    - **Введение в рекуррентные нейронные сети**
    - **Как рекуррентная нейронная сеть прогнозирует символы**
    - **Прогнозирование слов рекуррентной сетью**: Embedding слой
    - **Как работают RNN**: глубокие рекуррентные нейросети
    - **LSTM**: долгая краткосрочная память
    - **Сентимент-анализ рекуррентной LSTM сетью**
    - **Рекуррентные блоки GRU**: пример реализации в задаче сентимент-анализа
    - **Двунаправленные (bidirectional) рекуррентные нейронные сети**

4. **Дополнительно**
    - **Автоэнкодеры**: что это и как работают
    - **Вариационные автоэнкодеры (VAE)**: что это такое?
    - **Создание вариационного автоэнкодера (VAE) в Keras**
    - **Расширенный вариационный автоэнкодер (CVAE)**
    - **Генеративно-состязательные сети (GAN)**: что это такое?
    - **Создание генеративно-состязательной сети в Keras и Tensorflow**

### Требования

- Python 3.x
- TensorFlow
- Keras
- Jupyter Notebook

### Установка

1. Клонируйте репозиторий:
    ```bash
    git clone https://github.com/kisdspy/Intro-to-Neural-Networks.git
    ```
2. Установите необходимые библиотеки:
    ```bash
    pip install -r requirements.txt
    ```

### Начало работы

Откройте Jupyter Notebook и следуйте шагам, представленным в ноутбуках курса. Примеры и объяснения, дополняющие материал курса, будут предоставлены в каждом разделе.

### Авторы

- **Сергей Балакириев** - Автор курса
- **Илья Холостов** - Дополнительные примеры и пояснения с использованием ChatGPT

### Лицензия

Этот проект лицензирован под лицензией MIT - подробности см. в файле [LICENSE](LICENSE).


